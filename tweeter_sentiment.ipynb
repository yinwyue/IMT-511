{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a6 - Tweeter Sentiment\n",
    "\n",
    "In this assignment you will write a program to perform simple [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) of Twitter data&mdash;that is, determining the \"attitude\" or \"emotion\" (e.g., how \"positive\", \"negative\", \"joyful\", etc) of tweets made by a particular Twitter user. Sentiment analysis is a fascinating field: researchers have shown that the \"mood\" of Twitter communication [reflects biological rhythms](http://www.nytimes.com/2011/09/30/science/30twitter.html) and can even be used to [predict the stock market](http://arxiv.org/pdf/1010.3003&embedded=true). The particular analysis you'll be performing is inspired by an investigation of [personal vs. organizational tweets](http://varianceexplained.org/r/trump-tweets/) (which has become less amusing over time).\n",
    "\n",
    "You will be implementing a Python program that performs this analysis on **real data** taken directly from a Twitter user's timeline. In the end, your script will produce output similar to the following:\n",
    "\n",
    "```\n",
    "EMOTION       % WORDS  EXAMPLE WORDS                     HASHTAGS\n",
    "positive      6.16%    learn, faculty, happy             #accesstoinfoday, #indigenouspeoplesday, #idealistfair\n",
    "trust         3.08%    school, faculty, happy            #indigenouspeoplesday, #diversity\n",
    "anticipation  2.53%    happy, top, ready                 #indigenouspeoplesday, #informatics, #info340\n",
    "joy           1.76%    happy, peace, deal                #indigenouspeoplesday, #accesstoinfoday\n",
    "surprise      0.99%    deal, award, surprised            #suzzallolibrary, #nobrainer\n",
    "negative      0.88%    fall, rejection, outstanding        \n",
    "sadness       0.55%    fall, rejection, problem            \n",
    "disgust       0.44%    rejection, weird, finally           \n",
    "fear          0.44%    rejection, surprise, problem        \n",
    "anger         0.33%    rejection, disaster, involvement  #mlis\n",
    "```\n",
    "\n",
    "(The \"hashtags\" column is optional extra credit).\n",
    "\n",
    "Fill in the below code cells as specified. Note that cells may utilize variables and functions defined in previous cells; we should be able to use the `Kernal > Restart & Clear All` menu item followed by `Cell > Run All` to execute your entire notebook and see the correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "You'll be working with two different pieces of data for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you'll be loading tweet data taken directly from [Twitter's API](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline). You can find an example of this tweet data in the **`uw_ischool_sample.py`** file inside the `data/` folder. The below cell will import this data as a variable `SAMPLE_TWEETS` from the provided _module_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from uw_ischool_sample file in the `data/` package (folder)\n",
    "from data.uw_ischool_sample import SAMPLE_TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is represented as one giant **list of dictionaries**: the **list** contains a sequence of **dictionaries**, where each dictionary represents a tweet. Each dictionary contains many different _values_, some of which themselves may be dictionaries!\n",
    "\n",
    "Print out the first three elements from the `SAMPLE_TWEETS` list to see what information can be found in each. The most relevant value is the `\"text\"` of the tweet.\n",
    "- The Twitter API actually provides a lot more information about each tweet; I've stripped it down to only the most important values for readability. Each dictionary in the example is a proper subset of the full data you'd get from Twitter.\n",
    "- Because of the source of the sentiment data, your analysis will be biased and only support English-language speakers. Nevertheless, Twitter is an international community so you may encounter non-English characters and words. You'll be working with real-world data and it will be messy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created_at': 'Mon Oct 10 18:39:51 +0000 2016', 'retweet_count': 9, 'entities': {'hashtags': [{'indices': [20, 41], 'text': 'IndigenousPeoplesDay'}]}, 'user': {'screen_name': 'UW_iSchool'}, 'text': 'RT @UWAPress: Happy #IndigenousPeoplesDay https://t.co/YmU9e9lj7v'}, {'created_at': 'Mon Oct 10 18:00:00 +0000 2016', 'retweet_count': 0, 'entities': {'hashtags': [{'indices': [16, 29], 'text': 'IdealistFair'}]}, 'user': {'screen_name': 'UW_iSchool'}, 'text': \"We'll be at the #IdealistFair this evening on the Seattle U. campus. Come and learn about our graduate programs: https://t.co/et1HrQshmr\"}, {'created_at': 'Mon Oct 10 15:10:36 +0000 2016', 'retweet_count': 1, 'entities': {'hashtags': []}, 'user': {'screen_name': 'UW_iSchool'}, 'text': 'RT @iYouthUW: iYouth Tips for 1st\\xa0Years https://t.co/K4SCIEhJ8k https://t.co/p4lbC6Jb5o'}]\n"
     ]
    }
   ],
   "source": [
    "print(SAMPLE_TWEETS[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second piece of data you'll be working with is a set of **word-sentiments**&mdash;a set of English-language words and what emotions (e.g., \"joy\", \"anger\") [are associated with them](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm).\n",
    "\n",
    "- The [nltk](https://github.com/nltk/nltk/wiki/Sentiment-Analysis) library you used in a previous assignment does support sentiment analysis. However, for practice and extendability you'll be doing a more \"manual\" analysis using the provided data file for this assignment. You must _not_ use that library in this assignment!\n",
    "\n",
    "`import` the word sentiments as a variable **`SENTIMENTS`** from the **`data.sentiments_nrc`** module. You should also import the **`EMOTIONS`** variable provided by the same module: this is a _list_ of possible emotions (as strings). You can inspect the variables (e.g., print them out) to confirm that you have imported them, as well as to see what they look like.\n",
    "\n",
    "- Notice that `SENTIMENTS` is a _dictionary_ whose keys are English-language words (e.g., \"sunshine\", \"rainy\"). Each key points to a _another dictionary_, whose keys are _emotions_ (e.g., \"happy\", \"sad\") that go with that word. Thus `SENTIMENTS['sunshine']` will give you a dictionary of emotions for the word \"sunshine\", and `SENTIMENTS['sunshine'].get(\"happy\")` will let you know if the word \"sunshine\" is a happy word or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 1, 'joy': 1}\n",
      "None\n",
      "['positive', 'negative', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n"
     ]
    }
   ],
   "source": [
    "from data.sentiments_nrc import SENTIMENTS\n",
    "from data.sentiments_nrc import EMOTIONS\n",
    "\n",
    "print(SENTIMENTS[\"sunshine\"])\n",
    "\n",
    "print(SENTIMENTS['sunshine'].get(\"happy\"))\n",
    "print(EMOTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Sentiment\n",
    "All of the sentiment analysis will be based on the individual _words_ in the text. Thus you will need to will determine which words in a tweet have which sentiments.\n",
    "\n",
    "- Note that the assignment explicitly does _not_ tell you what to name functions, what arguments they should take or values they should return: your task is to determine appropriate functions and arguments from the (guided) requirements! Use multiple functions for clarity and give them all informative names! Try to make each function \"stand alone\"--so that it takes any information it needs as argumets, and then returns any information that it determines to be used elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that take a tweet's text (a string) and splits it up into a list of individual words.\n",
    "\n",
    "- You must **not** use the `nltk` library to tokenize words. Instead, your analysis must split up the text using the [regular expression](https://www.regular-expressions.info/) **`\"\\W+\"`** as a separator to \"split up\" the words by (rather than just a blank space). You can do this by using the [re.split()](https://docs.python.org/3/library/re.html#re.split) function (from the `re` module)--pass the function the separator string and then the string you wish to split, and it will return the split up list. Using `\"\\W+\"` as a separator will cause your spitting to exclude punctuation and provide a reasonable (but not perfect!) list of words to consider. \n",
    "\n",
    "- All of the words in the sentiment dictionary are _lower case_, so you'll need to **map** your resulting words to be lower case. You will also need to **filter** out any words that have 1 letter or fewer. Your function must use a **list comprehension** to do both of these.\n",
    "\n",
    "To test your work, the string `\"Amazingly, I prefer a #rainy day to #sunshine.\"` should produce a list with 6 lower-case words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazingly', 'prefer', 'rainy', 'day', 'to', 'sunshine']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take in a string and return a list with the words with more than 1 letter in the lower-case.\n",
    "import re\n",
    "def longword(word):\n",
    "    return len(word) > 1\n",
    "def get_words(string):\n",
    "    wordlist = re.split(r'\\W+', string.lower())\n",
    "    result = list(filter(longword, wordlist))\n",
    "    return result\n",
    "\n",
    "get_words(\"Amazingly, I prefer a #rainy day to #sunshine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that **filters** a list of words to get a list of only those words that contain a specific emotion. Your function must use a **list comprehension** to do this.\n",
    "- You can determine whether a word has a particular emotion by looking it up in the imported `SENTIMENTS` variable. Use the word as the \"key\" to find the dictionary of emotions for that word, and then use the emotion as the key to _that_ dictionary to determine if the word has it. \n",
    "    \n",
    "    Do **not** use the `in` operator or a loop to search the list of keys one by one. Instead, use bracket notation or the `get()` method to \"look up\" a key directly (this is more efficient and is why the emotions are nested dictionaries in the first place!).\n",
    "    \n",
    "For testing, the `\"positive\"` words extracted from `\"Amazingly, I prefer a #rainy day to #sunshine.\"` are `[\"amazingly\", \"prefer\", \"sunshine\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazingly', 'prefer', 'sunshine']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take in the string and the list of specific emotions. Return a list of words that has the emotion.\n",
    "def get_emotion(words_list, emotion):\n",
    "    #loop through the list to see if each of the words has a emotion.\n",
    "    emotion_words = []\n",
    "    for word in words_list:\n",
    "        #If the word is in the SENTIMNTS dictionary\n",
    "        if SENTIMENTS.get(word):\n",
    "             if SENTIMENTS[word].get(emotion) == 1:\n",
    "                 #append the emotion in a new list\n",
    "                 emotion_words.append(word)\n",
    "    return emotion_words\n",
    "\n",
    "\n",
    "test_string = \"Amazingly, I prefer a #rainy day to #sunshine.\"\n",
    "test_list = get_words(test_string)\n",
    "get_emotion(test_list, 'positive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that determines which words from a list have _each_ emotion (i.e., the \"emotional\" words), producing a dictionary of that information. For example, the words extracted from `\"Amazingly, I prefer a #rainy day to #sunshine.\"` should produce a dictionary that looks like:\n",
    "\n",
    "```\n",
    "{\n",
    " 'positive': ['amazingly', 'prefer', 'sunshine'],\n",
    " 'negative': [],\n",
    " 'anger': [],\n",
    " 'anticipation': [],\n",
    " 'disgust': [],\n",
    " 'fear': [],\n",
    " 'joy': ['amazingly', 'sunshine'],\n",
    " 'sadness': ['rainy'],\n",
    " 'surprise': ['amazingly'],\n",
    " 'trust': ['prefer']\n",
    "}\n",
    "```\n",
    "    \n",
    "(Note the empty lists for emotions that have no matching words).\n",
    "    \n",
    "- You can use the imported `EMOTIONS` variable to have a list of emotions to iterate through.\n",
    "- Use the function you defined in the previous step to help you out!\n",
    "- Using a [dictionary comprehension](https://www.smallsurething.com/list-dict-and-set-comprehensions-by-example/) is a nice way to do this, but is not required&mdash;using a regular loop is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': ['amazingly', 'prefer', 'sunshine'],\n",
       " 'negative': [],\n",
       " 'anger': [],\n",
       " 'anticipation': [],\n",
       " 'disgust': [],\n",
       " 'fear': [],\n",
       " 'joy': ['amazingly', 'sunshine'],\n",
       " 'sadness': ['rainy'],\n",
       " 'surprise': ['amazingly'],\n",
       " 'trust': ['prefer']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotion_dictionary(string):\n",
    "    emotion_dictionary = {}\n",
    "    words = get_words(string)\n",
    "    #loop through the emotions\n",
    "    for emotion in EMOTIONS:\n",
    "        #find the words for each emotion\n",
    "        emotion_word = get_emotion(words, emotion)\n",
    "        emotion_dictionary[emotion] = emotion_word\n",
    "    return emotion_dictionary\n",
    "\n",
    "emotion_dictionary(test_string)\n",
    "\n",
    "    #['positive', 'negative', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that gets a list of the \"most common\" words in a list. This should be a new list containing each word in the original list, in descending order by how many times that word appears in the orignal list.\n",
    "\n",
    "- You can determine the _frequency_ (number of occurrences) of a word with a similar process to what you did with digits in the previous assignment.\n",
    "- You can use the `sorted()` function to [sort](https://wiki.python.org/moin/HowTo/Sorting) the items in a frequency dictionary. This function accepts a [**key**](https://wiki.python.org/moin/HowTo/Sorting#Key_Functions) argument which is passed the name of a \"mapping\" function that maps an element (e.g., an item tuple) into the value you wish to sort by (e.g., the element of the tuple). An anonymous lambda function works well for this callback, but is not necessary.\n",
    "\n",
    "You can test this function with any list of \"words\" with repeated entries: `['a','b','c','c','c','a']` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "def count_frequency(wordlist):\n",
    "    wordlist = sorted(wordlist)\n",
    "    start_word = wordlist[0]\n",
    "    wordcount = 1\n",
    "    new_list = []\n",
    "    for element in wordlist[1:]:\n",
    "        if element == start_word:\n",
    "            wordcount += 1\n",
    "        else:\n",
    "            new_list.append((start_word, wordcount))\n",
    "            start_word = element\n",
    "            wordcount = 1\n",
    "    new_list.append((start_word, wordcount))\n",
    "    return new_list\n",
    "\n",
    "def get_word_from_tuple(list_tuple):\n",
    "    list_word = []\n",
    "    for tup in list_tuple:\n",
    "        list_word.append(tup[0])\n",
    "    return list_word\n",
    "\n",
    "def sort_frequency(wordlist):\n",
    "    frequency_list = count_frequency(wordlist)\n",
    "    word_frequency = sorted(frequency_list, key=lambda frequency: frequency[1], reverse = True)\n",
    "    result = get_word_from_tuple(word_frequency)\n",
    "    return result\n",
    "\n",
    "\n",
    "testlist = ['a','b','c','c','c','a']\n",
    "\n",
    "print(sort_frequency(testlist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Statistics\n",
    "Once you are able to determine the sentiment of an individual string of text (e.g., a single tweet's content), you can analyze an entire set of tweets from a user's timeline. Note that I am _not_ telling you how to break this process up into individual functions&mdash;you should be able to determine that on your own by this point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function (e.g., `analyze_tweets()`) that takes as an argument a **list** of tweet data (with the same structure as the imported `SAMPLE_TWEETS` variable), and _returns_ the data of interest to display in a table like the one at the very top of the notebook. In particular, you'll need to produce the following information **for each emotion**:\n",
    "\n",
    "1. The percentage of words _across all tweets_ that have that emotion\n",
    "2. The most common words _across all tweets_ that have that emotion (in order!)\n",
    "\n",
    "(Think carefully: should this data be stored in a _list_ or a _dictionary_?)\n",
    "\n",
    "Some tips for this task:\n",
    "\n",
    "- You can and should create some \"helper\" functions to break up this task even further. You can define those functions in the same notebook cell or you may insert additional cells below these instructions.\n",
    "\n",
    "- You'll need to use your previous functions to get the _list of words_ and _dictionary of emotional words_ for each tweet. I recommend you assign the results of these methods as **new values** of the respective tweet dictionary (so each tweet dictionary would gain a `words` key and a `sentiments` key, for example).\n",
    "\n",
    "- In order to get the percentage of emotional words, divide the number of words that have that emotion by the total number of words _across all the tweets_. Counting how many total words are in the tweet set is a **reducing** operation. As an **optional advanced requirement**, do this using the `reduce()` function.\n",
    "\n",
    "- For each emotion, you'll need to get a list of the words _across all the tweets_ that have that emotion (in order to determine how many there are for the percentage, as well as which are most common). This is another **reducing** operation. It is possible to use the built-in `sum()` function, or as an **optional advanced requirement** use the `reduce()` function.\n",
    "\n",
    "You can test your function by passing in the `SAMPLE_TWEETS` variable as an argument and checking if your returned data has the same numbers as in the table at the top of the page. Note that only the first 3 most common words are listed in the example (and may be in a different order in the case of frequency ties!).\n",
    "- For testing, my solution counts 909 total words in the sample; 56 of those words are \"positive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion': 'positive', 'percentage': '6.16%', 'common words': ['faculty', 'learn', 'happy']}, {'emotion': 'trust', 'percentage': '3.08%', 'common words': ['school', 'faculty', 'happy']}, {'emotion': 'anticipation', 'percentage': '2.53%', 'common words': ['happy', 'ready', 'top']}, {'emotion': 'joy', 'percentage': '1.76%', 'common words': ['happy', 'award', 'deal']}, {'emotion': 'surprise', 'percentage': '0.99%', 'common words': ['award', 'deal', 'disaster']}, {'emotion': 'negative', 'percentage': '0.88%', 'common words': ['fall', 'boring', 'disaster']}, {'emotion': 'sadness', 'percentage': '0.55%', 'common words': ['fall', 'disaster', 'problem']}, {'emotion': 'disgust', 'percentage': '0.44%', 'common words': ['disaster', 'finally', 'rejection']}, {'emotion': 'fear', 'percentage': '0.44%', 'common words': ['disaster', 'problem', 'rejection']}, {'emotion': 'anger', 'percentage': '0.33%', 'common words': ['disaster', 'involvement', 'rejection']}]\n"
     ]
    }
   ],
   "source": [
    "# Get the text of tweet from the SAMPLE_TWEETS\n",
    "def get_tweets(sample_tweets):\n",
    "    tweets = []\n",
    "    for dictionary in sample_tweets:\n",
    "        tweet = dictionary['text']\n",
    "        tweets.append(tweet)\n",
    "    return tweets\n",
    "\n",
    "# for all the tweets, add all the words into one list\n",
    "def get_word_from_tweet(list_tweets):\n",
    "    word_list = []\n",
    "    for tweet in list_tweets:\n",
    "        word_list += get_words(tweet)\n",
    "    return word_list\n",
    "\n",
    "def frequency_dictionary(tweet_word ,emotion,total_length):\n",
    "        word_have_emotion = get_emotion(tweet_word, emotion)\n",
    "        emotion_length = len(word_have_emotion)\n",
    "        percentage = round(emotion_length/total_length, 4)\n",
    "        word_frequency = sort_frequency(word_have_emotion)\n",
    "        dictionary= {'emotion':emotion, 'percentage': \"{:.2%}\".format(percentage), \"common words\": word_frequency[:3]}\n",
    "        return dictionary\n",
    "\n",
    "\n",
    "#Main\n",
    "def analyze_tweets(sample_tweets):\n",
    "    tweets_list = get_tweets(sample_tweets)\n",
    "    tweets_word = get_word_from_tweet(tweets_list)\n",
    "    total_length = len(tweets_word)\n",
    "    #Find the words that have a specific emotion:\n",
    "    analyze_result = []\n",
    "    for emotion in EMOTIONS:\n",
    "        dictionary = frequency_dictionary(tweets_word, emotion,total_length)\n",
    "        analyze_result.append(dictionary)\n",
    "    analyze_tweet = sorted(analyze_result, key=lambda  emotion: emotion['percentage'], reverse = True)\n",
    "    return analyze_tweet\n",
    "\n",
    "analyze_tweet = analyze_tweets(SAMPLE_TWEETS)\n",
    "print(analyze_tweet)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Optional extra credit***: For each emotion, also calculate the most common [**hashtags**](https://en.wikipedia.org/wiki/Hashtag) _across all tweets_ associated with that emotion. This means that out of all the weets that have _at least one word with that emotion_, what are the most common hashtags they use?\n",
    "\n",
    "- The Twitter data for each tweet includes a _list_ containing the hashtags found in that tweet&mdash;you should **NOT** try and search the tweet text for `#` symbols. These hashtags can be found in the `['entities']['hashtags'][i]['text']` element of each tweet&mdash;that is, the `'text'` key from _each_ element in the _list_ of the `'hashtags'` key in the `'entities'` dictionary of the tweet. See the `uw_school.json` example file to see this structure more clearly.\n",
    "\n",
    "    (You might use a _list comprehension_ to \"flatten\" this complex nesting structure into just a list of hashtag words).\n",
    "\n",
    "- Since hashtags are just words, you can use your function for finding the most common words to find the most common hashtags!\n",
    "\n",
    "- You can build your analysis into your previous `analyze_tweets()` function, or you can determine the hashtags using a second function (e.g., in the below cell).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Tweets \n",
    "\n",
    "Once you've analyzed the tweets, you will need to _display_ that information as a printed table (as in the example at the top of the page).\n",
    "\n",
    "Define another function to display this table (your function should take as an argument the data structure returned from your \"analysis\" function).\n",
    "\n",
    "This function will need to print out the table. Using the [string formatting](https://docs.python.org/3/library/string.html#format-examples) language (via the **`.format()`** string method) makes it possible to have equally sized \"columns\" of data. For more examples, [this tutorial](https://www.digitalocean.com/community/tutorials/how-to-use-string-formatters-in-python-3) is pretty good (check out the \"Padding Variable Substitutions\" section).\n",
    "\n",
    "\n",
    "A few notes about formatting this output:\n",
    "\n",
    "- For your reference, the example table at the top of the page uses `14` characters for the first column, `11` characters for the second,  `35` for the third, and the \"remainder\" for the fourth. You are not required to match these numbers.\n",
    "\n",
    "- The percentage should be formatted with two decimals of precision (e.g., `1.23%`).\n",
    "\n",
    "- Both the example sentiment words (and the hashtags, if you include them) should be outputted as a _comma-separated list_ with spaces between them&mdash;and no square brackets). The `join()` string method is good for converting lists to formatted strings. Both lists should also be limited to the 3 most common items for space.\n",
    "\n",
    "- Make sure to include `#` in front of the hashtags!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION        % WORDS     EXAMPLE WORDS                      \n",
      "positive       6.16%       faculty,learn,happy                \n",
      "trust          3.08%       school,faculty,happy               \n",
      "anticipation   2.53%       happy,ready,top                    \n",
      "joy            1.76%       happy,award,deal                   \n",
      "surprise       0.99%       award,deal,disaster                \n",
      "negative       0.88%       fall,boring,disaster               \n",
      "sadness        0.55%       fall,disaster,problem              \n",
      "disgust        0.44%       disaster,finally,rejection         \n",
      "fear           0.44%       disaster,problem,rejection         \n",
      "anger          0.33%       disaster,involvement,rejection     \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def table_display(analyze_tweet):\n",
    "    print(\"{0:<14} {1:<11} {2:<35}\".format('EMOTION','% WORDS','EXAMPLE WORDS'))\n",
    "    for dictionary in analyze_tweet:\n",
    "        commonword_list = dictionary['common words']\n",
    "        str = \",\"\n",
    "        seq = (commonword_list[0],commonword_list[1],commonword_list[2])\n",
    "        commonword = str.join(seq)\n",
    "        print(\"{0:<14} {1:<11} {2:<35}\".format(dictionary[\"emotion\"], dictionary['percentage'],commonword))\n",
    "\n",
    "print(table_display(analyze_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Live Data\n",
    "This is all good and well, but the real payoff is to be able to see the sentiments of tweets taken directly from the Twitter feed of real users!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define _another_ function (e.g., `get_user_tweets()`) that takes as an argument a Twitter username (as a string) then returns a list of dictionaries representing the tweets made by that user.\n",
    "\n",
    "I have set up a [proxy](https://en.wikipedia.org/wiki/Proxy) that you can use to send requests to [Twitter's API](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline) and access the data. You can thus get tweet data for a specific username at the URL:\n",
    "\n",
    "```\n",
    "https://faculty.washington.edu/joelross/proxy/twitter/timeline/?screen_name=SCREEN_NAME\n",
    "```\n",
    "\n",
    "(replacing `SCREEN_NAME` with the Twitter username).\n",
    "\n",
    "- _WARNING:_ The proxy I have set up is _rate-limited_ so that it can only accept 900 requests every 15 minutes. If all 40 students are working rapidly on the assignment at the same time, you may find yourself needing to wait a few minutes and try again. You are alternatively welcome to set up your own developer account and API keys; just make sure you don't put the keys under version control and upload them to GitHub!\n",
    "\n",
    "You can download the timeline data from Twitter using the [requests](http://docs.python-requests.org/en/master/user/quickstart/) module: use **`requests.get()`** to get a response from the above URL. Then call the **`.json()`** method on that response to extract the _list of dictionaries_ that your function will return. See [Chapter 12](https://infx511.github.io/accessing-web-apis.html#accessing-web-apis-1) of the course text for more details and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_user_tweets(username):\n",
    "    url = 'https://faculty.washington.edu/joelross/proxy/twitter/timeline/?screen_name=' + username\n",
    "    response = requests.get (url)\n",
    "    tweets = response.json()\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define one last \"main\" function that will [prompt the user](https://docs.python.org/3/library/functions.html#input) for a Twitter username. The function should then call your `get_user_tweets()` function to fetch the tweets, and pass the returned tweet data into your \"analyze\" and \"display\" functions in order to display your sentiment analysis of the user's timeline. \n",
    "\n",
    "**ADDITIONALLY**, your main function should check that `if` the user specifies `SAMPLE` (all caps) as the username, the function should instead show the analysis for the `SAMPLE_TWEETS` (this will help us out with grading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the user name: UW_iSchool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'emotion': 'positive',\n",
       "  'percentage': '7.33%',\n",
       "  'common words': ['director', 'launch', 'learn']},\n",
       " {'emotion': 'anticipation',\n",
       "  'percentage': '2.36%',\n",
       "  'common words': ['launch', 'public', 'plan']},\n",
       " {'emotion': 'trust',\n",
       "  'percentage': '1.89%',\n",
       "  'common words': ['director', 'real', 'center']},\n",
       " {'emotion': 'negative',\n",
       "  'percentage': '0.95%',\n",
       "  'common words': ['fight', 'liaison', 'quote']},\n",
       " {'emotion': 'joy',\n",
       "  'percentage': '0.71%',\n",
       "  'common words': ['pleased', 'proud', 'special']},\n",
       " {'emotion': 'surprise',\n",
       "  'percentage': '0.71%',\n",
       "  'common words': ['catch', 'quote', 'surprising']},\n",
       " {'emotion': 'fear',\n",
       "  'percentage': '0.47%',\n",
       "  'common words': ['fight', 'watch']},\n",
       " {'emotion': 'anger', 'percentage': '0.24%', 'common words': ['fight']},\n",
       " {'emotion': 'disgust', 'percentage': '0.24%', 'common words': ['interested']},\n",
       " {'emotion': 'sadness', 'percentage': '0.24%', 'common words': ['interested']}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main_function():\n",
    "    username = input('Enter the user name: ')\n",
    "    if username == \"SAMPLE\":\n",
    "        data = SAMPLE_TWEETS\n",
    "    else:\n",
    "        data = get_user_tweets(username)\n",
    "    analyze_data = analyze_tweets(data)\n",
    "    return analyze_data\n",
    "\n",
    "main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, call your main function to analyze the timeline of a Twitter user. You can even call it multiple times to compare the sentiments of different users. Are the current sentiments of the [iSchool](https://twitter.com/uw_ischool) and [CSE](https://twitter.com/uwcse) different in interesting ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the user name: uwcse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'emotion': 'positive',\n",
       "  'percentage': '5.31%',\n",
       "  'common words': ['join', 'expert', 'full']},\n",
       " {'emotion': 'trust',\n",
       "  'percentage': '3.14%',\n",
       "  'common words': ['expert', 'professor', 'school']},\n",
       " {'emotion': 'joy',\n",
       "  'percentage': '1.69%',\n",
       "  'common words': ['create', 'excitement', 'food']},\n",
       " {'emotion': 'negative',\n",
       "  'percentage': '1.45%',\n",
       "  'common words': ['coma', 'falling', 'forget']},\n",
       " {'emotion': 'anticipation',\n",
       "  'percentage': '0.97%',\n",
       "  'common words': ['excitement', 'improve', 'time']},\n",
       " {'emotion': 'anger',\n",
       "  'percentage': '0.72%',\n",
       "  'common words': ['kick', 'kicking', 'mosquito']},\n",
       " {'emotion': 'surprise',\n",
       "  'percentage': '0.72%',\n",
       "  'common words': ['catch', 'excitement']},\n",
       " {'emotion': 'fear',\n",
       "  'percentage': '0.48%',\n",
       "  'common words': ['coma', 'volunteer']},\n",
       " {'emotion': 'sadness',\n",
       "  'percentage': '0.48%',\n",
       "  'common words': ['coma', 'falling']},\n",
       " {'emotion': 'disgust', 'percentage': '0.24%', 'common words': ['mosquito']}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
